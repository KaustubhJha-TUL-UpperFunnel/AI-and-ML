{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['age','workclass', 'fnlwgt', 'education', 'education_num', \n",
    "           'marital','occupation', 'relationship', 'race', 'sex', \n",
    "           'capital_gain','capital_loss','hours_week','native_country',\n",
    "           'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Adult.csv', skipinitialspace=True, names = COLUMNS, index_col=False)\n",
    "df_test = pd.read_csv('Adult_Test.csv',skiprows = 1, skipinitialspace=True, names = COLUMNS, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15) (16281, 15)\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital           object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_week         int64\n",
      "native_country    object\n",
      "label             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)\n",
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {'<=50K': 0,'>50K': 1}\n",
    "df_train.label = [label[item] for item in df_train.label]\n",
    "label_t = {'<=50K.': 0,'>50K.': 1}\n",
    "df_test.label = [label_t[item] for item in df_test.label] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in df_train.label:\n",
    "    labprint(label[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    24720\n",
      "1     7841\n",
      "Name: label, dtype: int64\n",
      "0    12435\n",
      "1     3846\n",
      "Name: label, dtype: int64\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital           object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_week         int64\n",
      "native_country    object\n",
      "label              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"label\"].value_counts())\n",
    "### The model will be correct in atleast 70% of the case\n",
    "print(df_test[\"label\"].value_counts())\n",
    "## Unbalanced label\n",
    "print(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital_gain', 'education_num', 'capital_loss', 'hours_week']\n",
    "### Define the categorical list\n",
    "CATE_FEATURES = ['workclass', 'education', 'marital', 'occupation', 'relationship', 'race', 'sex', 'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39.]\n",
      " [50.]\n",
      " [38.]\n",
      " ...\n",
      " [58.]\n",
      " [22.]\n",
      " [52.]]\n"
     ]
    }
   ],
   "source": [
    "def print_transformation(feature, continuous = True, size = 2): \n",
    "    #X = fc.numeric_column(feature)\n",
    "    ## Create feature name\n",
    "    feature_names = [\n",
    "    feature]\n",
    "\n",
    "    ## Create dict with the data\n",
    "    d = dict(zip(feature_names, [df_train[feature]]))\n",
    "\n",
    "    ## Convert age\n",
    "    if continuous == True:\n",
    "        c = tf.feature_column.numeric_column(feature)\n",
    "        feature_columns = [c]\n",
    "    else: \n",
    "        c = tf.feature_column.categorical_column_with_hash_bucket(feature, hash_bucket_size=size) \n",
    "        c_indicator = tf.feature_column.indicator_column(c)\n",
    "        feature_columns = [c_indicator]\n",
    "    \n",
    "## Use input_layer to print the value\n",
    "    input_layer = tf.feature_column.input_layer(\n",
    "        features=d,\n",
    "        feature_columns=feature_columns\n",
    "        )\n",
    "    ## Create lookup table\n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    where = tf.not_equal(input_layer, zero)\n",
    "    ## Return lookup tble\n",
    "    indices = tf.where(where)\n",
    "    values = tf.gather_nd(input_layer, indices)\n",
    "    ## Initiate graph\n",
    "    sess = tf.Session()\n",
    "    ## Print value\n",
    "    print(sess.run(input_layer))\n",
    "print_transformation(feature = \"age\", continuous = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [tf.feature_column.numeric_column(k) for k in CONTI_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='fnlwgt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='hours_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'relationship', [\n",
    "        'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\n",
    "        'Other-relative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = [tf.feature_column.categorical_column_with_hash_bucket(k, hash_bucket_size=1000) for k in CATE_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_HashedCategoricalColumn(key='workclass', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='education', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='marital', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='occupation', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='relationship', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='race', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='sex', hash_bucket_size=1000, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='native_country', hash_bucket_size=1000, dtype=tf.string)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002320313E9B0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# model = tf.estimator.LinearRegressor(\n",
    "# \n",
    "# model_dir=\"ongoing/train\", \n",
    "# feature_columns=categorical_features+ continuous_features)\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    n_classes = 2,\n",
    "    model_dir=\"ongoing/train\", \n",
    "    feature_columns=categorical_features+ continuous_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURES = ['age','workclass', 'fnlwgt', 'education', 'education_num', 'marital', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_week', 'native_country']\n",
    "LABEL= 'label'\n",
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "       x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "       y = pd.Series(data_set[LABEL].values),\n",
    "       batch_size=n_batch,   \n",
    "       num_epochs=num_epochs,\n",
    "       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ongoing/train\\model.ckpt.\n",
      "INFO:tensorflow:loss = 27703.799, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 56.0468\n",
      "INFO:tensorflow:loss = 21282.248, step = 1101 (1.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.441\n",
      "INFO:tensorflow:loss = 19786.83, step = 1201 (0.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.047\n",
      "INFO:tensorflow:loss = 50617.586, step = 1301 (0.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.862\n",
      "INFO:tensorflow:loss = 11950.664, step = 1401 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.757\n",
      "INFO:tensorflow:loss = 9226.836, step = 1501 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.409\n",
      "INFO:tensorflow:loss = 15187.67, step = 1601 (0.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.914\n",
      "INFO:tensorflow:loss = 11714.3545, step = 1701 (0.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.916\n",
      "INFO:tensorflow:loss = 15464.248, step = 1801 (0.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.279\n",
      "INFO:tensorflow:loss = 15931.498, step = 1901 (0.756 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ongoing/train\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7355.2046.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x23203219ba8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=get_input_fn(df_train, \n",
    "                                      num_epochs=None,\n",
    "                                      n_batch = 128,\n",
    "                                      shuffle=False),\n",
    "                                      steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-31-11:10:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/train\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-31-11:10:31\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.7605798, accuracy_baseline = 0.76377374, auc = 0.6488761, auc_precision_recall = 0.5227026, average_loss = 31.89848, global_step = 2000, label/mean = 0.23622628, loss = 4057.3372, precision = 0.49222022, prediction/mean = 0.20502073, recall = 0.42771712\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: ongoing/train\\model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7605798,\n",
       " 'accuracy_baseline': 0.76377374,\n",
       " 'auc': 0.6488761,\n",
       " 'auc_precision_recall': 0.5227026,\n",
       " 'average_loss': 31.89848,\n",
       " 'global_step': 2000,\n",
       " 'label/mean': 0.23622628,\n",
       " 'loss': 4057.3372,\n",
       " 'precision': 0.49222022,\n",
       " 'prediction/mean': 0.20502073,\n",
       " 'recall': 0.42771712}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn=get_input_fn(df_test, \n",
    "                                      num_epochs=1,\n",
    "                                      n_batch = 128,\n",
    "                                      shuffle=False),\n",
    "                                      steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
